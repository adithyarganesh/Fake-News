{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fake_or_real_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With little fanfare this fall, the New York developer who had planned to build an Islamic community center north of the World Trade Center announced that he would instead use the site for a 70-story tower of luxury condos.\\n\\nThose who had rallied in opposition to the building because of its religious affiliation back in 2010 were exultant. “The importance of the defeat of the Ground Zero Mosque cannot be overstated,” Pamela Geller, president of the American Freedom Defense Initiative, wrote on the website Breitbart in September. “The Ground Zero Mosque became a watershed issue in our effort to raise awareness of and ultimately halt and roll back the advance of Islamic law and Islamic supremacism in America.”\\n\\nIt’s all well and good that so many Republicans have condemned Donald Trump’s reprehensible call for “a total and complete shutdown of Muslims entering the United States.” House Speaker Paul D. Ryan (Wis.) was particularly forceful, calling proper attention to the “many Muslims serving in our armed forces, dying for this country.”\\n\\nWhen he was president, George W. Bush honorably put a lid on right-wing Islamophobia. He regularly praised American Muslims and stressed that the United States needed Muslim allies to fight violent extremism. Once Bush was gone, restraint on his side of politics fell away.\\n\\nThus, Trump’s embrace of a religious test for entry to our country did not come out of nowhere. On the contrary, it simply brought us to the bottom of a slippery slope created by the ongoing exploitation of anti-Muslim feeling for political purposes.\\n\\nYou don’t have to reach far back in time to see why Trump figured he had the ideological space for his Muslim ban. Last month, it was Jeb Bush who introduced the idea of linking the rights of Syrian refugees to their religion. He said he was comfortable granting admission to “people like orphans and people who are clearly not going to be terrorists. Or Christians.” Asked how he’d determine who was Christian, he explained that “you can prove you’re a Christian.”\\n\\nSen. Ted Cruz (Tex.) took a similar view, saying , “There is no meaningful risk of Christians committing acts of terror.”\\n\\nTrump took limits on Muslim access to our country to their logical — if un-American and odious — conclusion. Vice President Biden said that Trump was serving up “a very, very dangerous brew,” but the brew has been steeping for a long time. This is why the “Ground Zero Mosque” episode is so instructive.\\n\\nThe demagoguery began with the labeling of the controversy itself. As PolitiFact pointed out, “the proposed mosque is not at or on Ground Zero. It does not directly abut it or overlook it.” It was “two long blocks” away. And while a mosque was part of the proposed cultural center, the plans also included “a swimming pool, gym and basketball court, a 500-seat auditorium, a restaurant and culinary school, a library and art studios.”\\n\\nThis didn’t stop opponents from going over the top, and Newt Gingrich deserved some kind of award for the most incendiary comment of all. “Nazis,” he said, “don’t have the right to put up a sign next to the Holocaust museum in Washington.”\\n\\nWhen President Obama defended the right of developers to build the project, he was — surprise, surprise — accused of being out of touch, and Republicans were happy to make the Muslim center and Obama’s defense of religious rights an issue in the 2010 campaign.\\n\\n“I think it does speak to the lack of connection between the administration and Washington and folks inside the Beltway and mainstream America,” said Sen. John Cornyn (Tex.), who was then chairman of the committee in charge of electing Republicans to the Senate. Voters, he said, felt they were “being lectured to, not listened to.” Sound familiar?\\n\\nAt the time, John Feehery, the veteran Republican strategist, put his finger on why Republicans were so eager to lambaste Obama’s response to the Ground Zero issue. “This will help drive turnout for the GOP base,” he said.\\n\\nThe Republican establishment is now all upset with Trump, but he is simply the revenge of a Republican base that took its leaders’ pandering — on Islam and a host of other issues — seriously.\\n\\nYou can’t be “just a little” intolerant of Muslims, any more than you can be “just a little” prejudiced against Catholics or Jews. Once the door to bigotry is opened, it is very hard to shut.\\n\\nRead more from E.J. Dionne’s archive, follow him on Twitter or subscribe to his updates on Facebook.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 4 columns):\n",
      "Unnamed: 0    6335 non-null int64\n",
      "title         6335 non-null object\n",
      "text          6335 non-null object\n",
      "label         6335 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d093750dfa42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\"dd\",\"ddd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [\"the quick brown fox jumped over the lazy\",\" dog the fox the dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = X[\"text\"][20].replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-9b54bd8448fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for i in b:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-cc4e6df8bae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = CountVectorizer()\n",
    "v = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\"the quick brown fox jumoed over the kazy dog\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.fit(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'back': 34, 'would': 384, 'out': 243, 'admission': 8, 'rallied': 270, 'seriously': 298, 'logical': 206, 'forces': 137, 'access': 4, 'pamela': 247, 'court': 85, 'obama': 230, 'thus': 342, 'wrote': 385, 'cornyn': 83, 'nowhere': 229, 'exploitation': 118, 'praised': 260, 'dangerous': 90, 'updates': 359, 'determine': 96, 'trade': 350, 'us': 361, 'states': 315, 'beltway': 44, 'initiative': 172, 'familiar': 123, 'created': 86, 'developer': 97, 'little': 205, 'have': 155, 'political': 256, 'they': 338, 'violent': 367, 'by': 57, 'he': 156, 'country': 84, 'and': 18, 'embrace': 112, 'auditorium': 30, 'top': 346, 'said': 290, 'facebook': 121, 'gingrich': 142, 'call': 58, 'president': 262, '2010': 0, 'gone': 144, 'trump': 351, 'felt': 129, 'site': 306, 'to': 344, 'has': 154, 'community': 75, 'luxury': 208, 'finger': 132, 'september': 297, 'anti': 20, 'tex': 331, 'awareness': 32, 'lid': 200, 'dying': 108, 'more': 214, 'all': 12, 'very': 363, 'once': 234, 'how': 164, 'use': 362, 'united': 357, 'senate': 296, 'with': 382, 'reach': 272, 'response': 281, 'project': 263, 'announced': 19, 'month': 213, 'also': 14, 'when': 375, 'leaders': 197, 'restraint': 283, 'think': 339, 'the': 334, 'electing': 111, 'plans': 254, 'needed': 221, 'labeling': 192, 'school': 292, 'itself': 186, 'twitter': 353, 'on': 233, 'accused': 5, 'fall': 122, 'particularly': 250, 'had': 150, 'being': 43, 'opposition': 238, 'fight': 130, 'culinary': 88, '70': 2, 'like': 201, 'most': 216, 'for': 135, 'swimming': 325, 'geller': 140, 'clearly': 69, 'planned': 253, 'entering': 113, 'attention': 29, 'his': 159, 'kind': 191, 'story': 318, 'basketball': 37, 'explained': 117, 'committing': 74, 'affiliation': 10, 'slope': 308, 'became': 39, 'far': 125, 'but': 56, 'will': 379, 'purposes': 267, 'ongoing': 235, 'steeping': 316, 'gym': 149, 'wis': 381, 'make': 210, 'extremism': 119, 'long': 207, 'vice': 365, 'charge': 66, 'space': 312, 'advance': 9, 'folks': 133, 'law': 196, 'gop': 146, 'veteran': 364, 'reprehensible': 278, 'comfortable': 71, 'feeling': 127, 'studios': 321, 'opened': 236, 'nazis': 220, 'why': 378, 'speak': 313, 'began': 42, 'art': 25, 'blocks': 48, 'jews': 188, 'subscribe': 322, 'shut': 300, 'politics': 257, 're': 271, 'figured': 131, 'fanfare': 124, 'raise': 269, 'door': 106, 'going': 143, 'acts': 6, 'bottom': 49, 'brought': 52, 'bush': 55, 'was': 369, 'right': 285, 'pointed': 255, 'roll': 288, 'ground': 148, 'ted': 327, 'john': 189, 'ban': 35, 'up': 358, 'christian': 67, '500': 1, 'many': 211, 'introduced': 177, 'base': 36, 'did': 99, 'good': 145, 'center': 64, 'their': 335, 'away': 33, 'it': 184, 'an': 17, 'cannot': 62, 'between': 45, 'because': 40, 'new': 222, 'asked': 27, 'this': 340, 'contrary': 81, 'then': 336, 'drive': 107, 'connection': 80, 'un': 356, 'simply': 305, 'religious': 277, 'museum': 217, 'breitbart': 50, 'christians': 68, 'happy': 152, 'islam': 179, 'if': 167, 'two': 354, 'lambaste': 194, 'donald': 105, 'just': 190, 'those': 341, 'entry': 114, 'america': 15, 'listened': 204, 'demagoguery': 94, 'of': 232, 'abut': 3, 'bigotry': 47, 'overstated': 246, 'wing': 380, 'people': 252, 'surprise': 324, 'prejudiced': 261, 'idea': 165, 'religion': 276, 'armed': 24, 'does': 103, 'orphans': 240, 'while': 376, 'host': 162, 'turnout': 352, 'there': 337, 'some': 310, 'as': 26, 'halt': 151, 'touch': 348, 'so': 309, 'limits': 202, 'stressed': 320, 'issue': 182, 'not': 227, 'upset': 360, 'muslim': 218, 'pandering': 248, 'next': 224, 'fell': 128, 'republicans': 280, 'issues': 183, 'side': 302, 'dionne': 101, 'north': 226, 'overlook': 245, 'episode': 115, 'see': 294, 'is': 178, 'controversy': 82, 'prove': 266, 'condemned': 78, 'directly': 102, 'republican': 279, 'included': 171, 'award': 31, 'odious': 231, 'jeb': 187, 'forceful': 136, 'house': 163, 'ultimately': 355, 'committee': 73, 'zero': 388, 'opponents': 237, 'watershed': 371, 'sen': 295, 'establishment': 116, 'lack': 193, 'now': 228, 'freedom': 138, 'cruz': 87, 'eager': 109, 'last': 195, 'stop': 317, 'you': 387, 'library': 199, 'defense': 93, 'ideological': 166, 'feehery': 126, 'american': 16, 'be': 38, 'speaker': 314, 'proper': 264, 'similar': 304, 'conclusion': 77, 'catholics': 63, 'our': 242, 'exultant': 120, 'follow': 134, 'washington': 370, 'ryan': 289, 'syrian': 326, 'are': 23, 'view': 366, 'part': 249, 'incendiary': 170, 'website': 372, 'time': 343, 'well': 373, 'supremacism': 323, 'other': 241, 'test': 330, 'george': 141, 'inside': 173, 'proposed': 265, 'from': 139, 'total': 347, 'no': 225, 'at': 28, 'intolerant': 176, 'islamophobia': 181, 'help': 157, 'chairman': 65, 'hard': 153, 'brew': 51, 'politifact': 258, 'campaign': 60, 'islamic': 180, 'muslims': 219, 'cultural': 89, 'that': 333, 'its': 185, 'been': 41, 'any': 21, 'sign': 303, 'mosque': 215, 'lectured': 198, 'regularly': 275, 'or': 239, 'took': 345, 'put': 268, 'condos': 79, 'building': 54, 'were': 374, 'world': 383, 'in': 169, 'seat': 293, 'york': 386, 'terrorists': 329, 'slippery': 307, 'allies': 13, 'strategist': 319, 'risk': 287, 'comment': 72, 'refugees': 274, 'honorably': 161, 'who': 377, 'granting': 147, 'defended': 92, 'meaningful': 212, 'sound': 311, 'come': 70, 'calling': 59, 'saying': 291, 'can': 61, 'voters': 368, 'serving': 299, 'linking': 203, 'terror': 328, 'importance': 168, 'over': 244, 'against': 11, 'instead': 174, 'deserved': 95, 'tower': 349, 'newt': 223, 'archive': 22, 'pool': 259, 'restaurant': 282, 'than': 332, 'read': 273, 'holocaust': 160, 'rights': 286, 'administration': 7, 'defeat': 91, 'didn': 100, 'mainstream': 209, 'instructive': 175, 'shutdown': 301, 'effort': 110, 'complete': 76, 'biden': 46, 'build': 53, 'don': 104, 'paul': 251, 'developers': 98, 'him': 158, 'revenge': 284}\n",
      "[ 1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.          1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.          1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.          1.          1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.          1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.          1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.          1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511]\n"
     ]
    }
   ],
   "source": [
    "print(v.vocabulary_)\n",
    "print(v.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = v.transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  1,  1,  2,  3,\n",
       "         2, 19,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  2,\n",
       "         3,  1,  2,  1,  4,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,\n",
       "         2,  1,  2,  1,  3,  2,  1,  1,  1,  1,  3,  1,  1,  4,  1,  1,  2,\n",
       "         2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  9,\n",
       "         1,  1,  1,  2,  1,  1,  1,  2,  1,  1,  1,  1,  5,  1,  3,  1,  1,\n",
       "         1,  1,  3, 13,  1,  1,  4,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  8,  1,  3,  1,  3,  1,  9,  2,  1,\n",
       "         1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  3,  1,  2,  1,  1,  1,  2,  1,  1,  2,  5,  1,  1,  5,  4,  1,\n",
       "         1,  1,  1,  1,  1,  1,  5,  1,  1,  3,  1, 32, 10,  2,  1,  1,  1,\n",
       "         1,  5,  1,  1,  4,  3,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  2,  1,  1,  3,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  3,  1,  3,  4,  1,  1,  1,  1,  3,  2,  1,  1,\n",
       "         1,  6,  1,  1,  1,  1,  2,  1,  1,  1,  2,  1,  1,  1,  1,  1,  2,\n",
       "         1,  1,  1,  3,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  2,  1,  1,  1,  1,  1,  1,  2,  1,  6, 48,  2,  1,  1,  1,  1,\n",
       "         5,  1,  1,  3, 27,  3,  1,  1,  1,  1,  1,  6,  1,  1,  1,  1,  1,\n",
       "         2,  2,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1, 11,  2,  1,  1,  1,\n",
       "         4,  2,  1,  6,  3,  1,  1,  1,  3,  1,  1,  1,  1,  5,  5]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = X['text'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = v.transform(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
